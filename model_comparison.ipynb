{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae9aca7",
   "metadata": {},
   "source": [
    "# Public Policy Sentiment Analysis — CoWIN Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6291db37-c221-4cee-8acc-1343db2c8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_with_sentiment.csv')\n",
    "df = df.rename(columns={'created_at': 'timestamp', 'predicted_sentiment_roberta': 'sentiment'})\n",
    "\n",
    "# Filter first while 'lang' still exists\n",
    "df = df[df['lang'] == 'en']\n",
    "\n",
    "# Then keep relevant columns\n",
    "df = df[['timestamp', 'text', 'sentiment', 'like_count', 'retweet_count']]\n",
    "df['sentiment'] = df['sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f197af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a32991-b900-4c17-b786-dae693216eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "(470854, 5)\n",
      "                  timestamp  \\\n",
      "0  2021-01-02T13:49:32.000Z   \n",
      "1  2021-01-02T13:34:38.000Z   \n",
      "2  2021-01-02T13:03:35.000Z   \n",
      "3  2021-01-02T12:28:17.000Z   \n",
      "4  2021-01-02T12:18:09.000Z   \n",
      "\n",
      "                                                text sentiment  like_count  \\\n",
      "0  @user @user @user @user Hi, can you please sha...  positive           0   \n",
      "1  @user Could not find #CoWIN #CowinApp on play ...  negative           0   \n",
      "2                            @user @user Cowin lush!  positive           2   \n",
      "3  <U+25B6><U+FE0F> #COVID19 Vaccine Dry Run Held...  positive           3   \n",
      "4  Covid vaccination India dry run how to registe...  positive           0   \n",
      "\n",
      "   retweet_count  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset loaded successfully!\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f43882-269b-4cf0-863c-bddae5fd23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'http\\\\S+', '', s)\n",
    "    s = re.sub(r'@\\\\w+', '', s)\n",
    "    s = re.sub(r'[^A-Za-z\\\\s]', '', s)  # remove emojis/punctuations\n",
    "    s = re.sub(r'\\\\s+', ' ', s).strip()\n",
    "    return s.lower()\n",
    "\n",
    "df['clean_text'] = df['text'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddd043d-12bd-4a14-b7d5-56c1c5fae9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 376683 | Testing samples: 94171\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['sentiment'], random_state=42)\n",
    "\n",
    "X_train, y_train = train_df['clean_text'], train_df['sentiment']\n",
    "X_test, y_test = test_df['clean_text'], test_df['sentiment']\n",
    "\n",
    "print(f\"Training samples: {len(X_train)} | Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71155f9c-afea-4afa-8780-05736328e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.30      1.00      0.47     10982\n",
      "    positive       1.00      0.70      0.82     83189\n",
      "\n",
      "    accuracy                           0.73     94171\n",
      "   macro avg       0.65      0.85      0.64     94171\n",
      "weighted avg       0.92      0.73      0.78     94171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=50000, ngram_range=(1,2), min_df=5)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='saga', C=1.0, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Report ===\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open('models/tfidf_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe_lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba975c9-ed12-4c72-a1c4-bf5d2299489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 939/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4:47\u001b[0m 744ms/step - accuracy: 0.8831 - loss: 0.2769"
     ]
    }
   ],
   "source": [
    "MAX_WORDS = 30000\n",
    "MAX_LEN = 120\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=MAX_LEN)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=MAX_LEN)\n",
    "\n",
    "# Encode labels (convert positive/negative to 1/0)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "    Bidirectional(LSTM(128, return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "mc = ModelCheckpoint('models/lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_enc,\n",
    "    validation_split=0.1,\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    callbacks=[es, mc],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_lstm = (model.predict(X_test_seq) > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\n=== LSTM Report ===\")\n",
    "print(classification_report(y_test_enc, y_pred_lstm))\n",
    "\n",
    "# Save tokenizer & label encoder\n",
    "with open('models/tokenizer_lstm.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "with open('models/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b84190-6c3e-42f3-bdd6-993f2b4e7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'BiLSTM'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_lr),\n",
    "        accuracy_score(y_test_enc, y_pred_lstm)\n",
    "    ],\n",
    "    'F1': [\n",
    "        f1_score(y_test, y_pred_lr, pos_label='positive', average='binary'),\n",
    "        f1_score(y_test_enc, y_pred_lstm)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(results)\n",
    "\n",
    "results.to_csv('models/model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd9b76b-0a89-48a0-99c4-25013f9a59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Model', y='Accuracy', data=results)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6262a-06ce-49b9-a138-c82609baf1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
